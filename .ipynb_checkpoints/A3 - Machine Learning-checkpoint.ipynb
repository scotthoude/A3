{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading all of the data files, all at 100mhz or 100 samples per second\n",
    "# Thanks to Katie for her files, I needed the sitting, jogging and stairs ones,\n",
    "# the others are my own\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "# these magic rows make the long floats in a np array all output nicely for display\n",
    "float_formatter = lambda x: \"%.3f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "clsTrain = [] # this is store my array of classifiers (0-4) - kinda hacky but it works\n",
    "clsTest = []\n",
    "\n",
    "#This takes in the csv files and returns an array that can be used for machine learning\n",
    "#also returns the header row which is the same for all of my files\n",
    "def load_files(input_file, cls_num):\n",
    "    output_array = []\n",
    "    input_headers = []\n",
    "    with open(input_file, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        input_headers = reader.next() #saves the headers\n",
    "        for row in reader:\n",
    "            output_array.append(row[1:]) # Don't need the timestamp\n",
    "    \n",
    "    input_headers = input_headers[1:] # again - don't need the timestamp\n",
    "    # Convert to a dict to make using it easier later on\n",
    "    output_headers = {}\n",
    "    for i in range(len(input_headers)):\n",
    "        output_headers[i] = input_headers[i]\n",
    "            \n",
    "    # Prior testing gave me the size of the files so I know I can skip the first 10 seconds (1000 rows)\n",
    "    # and then take the next 30,000 records to get 30 - 10 second chunks\n",
    "    # never forget that it's all zero indexed\n",
    "    output_array = output_array[999:30999]\n",
    "    \n",
    "    # Now let's reduce down to 10 second chunks aka 1000 rows\n",
    "    compressed = []\n",
    "    n = 0\n",
    "    temp = []\n",
    "    \n",
    "    for row in output_array:\n",
    "        temp.append(row)\n",
    "        n +=1\n",
    "        if n == 1000: \n",
    "            temp = np.array(temp).astype(float) #convert to a numpy float array so I can do the next line\n",
    "            compressed.append(temp.mean(axis=0).tolist()) #this averages by columns and makes it a list of lists\n",
    "            temp = []\n",
    "            n = 0\n",
    "            \n",
    "    # I use this to build the 'y' or classifier array for use later\n",
    "    for i in range(30):\n",
    "        if i < 24:\n",
    "            clsTrain.append(cls_num)\n",
    "        else:\n",
    "            clsTest.append(cls_num)\n",
    "            \n",
    "\n",
    "    return compressed, output_headers\n",
    "    \n",
    "# rawWalkValues, Labels = load_files(\"walking2.csv\",0) # my walking - which doesn't play well with Katie's movement data\n",
    "rawWalkValues, Labels = load_files(\"Walking-katie.csv\",0) # Katie's walking\n",
    "rawSittingValues, Labels = load_files(\"sitting.csv\",1)\n",
    "rawCarValues, Labels = load_files(\"car.csv\",2)\n",
    "rawJogValues, Labels = load_files(\"Jogging.csv\",3)\n",
    "rawStairsValues, Labels = load_files(\"Steps.csv\",4)\n",
    "\n",
    "# This dictionary helps translate from an int to the type of activity downstream\n",
    "dataType = {0:'Walking', 1:'Sitting', 2:'Car', 3:'Jogging', 4:'Stairs'}\n",
    "\n",
    "# put everything together into one merged training and then seperate test sets\n",
    "# first 24 records from each  train, last 6 = testing\n",
    "allTrain = rawWalkValues[:24] + rawSittingValues[:24] + rawCarValues[:24] + rawJogValues[:24] + rawStairsValues[:24]\n",
    "walkTest = rawWalkValues[24:] \n",
    "sitTest = rawSittingValues[24:]\n",
    "carTest = rawCarValues[24:]\n",
    "jogTest = rawJogValues[24:]\n",
    "stairsTest = rawStairsValues[24:]\n",
    "allTest = rawWalkValues[24:] + rawSittingValues[24:] + rawCarValues[24:] + rawJogValues[24:] + rawStairsValues[24:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This block is just to test my data loads and various setup stuff from the block above\n",
    "# Feel free to use it to see anything in particular\n",
    "# print Labels\n",
    "# print rawWalkValues[0]\n",
    "# print clsTrain\n",
    "# print len(rawWalkValues[:24])\n",
    "# print dataType[0]\n",
    "\n",
    "#Testing the length of the arrays, I should have 30 records after chunking into 10 second sections by / 1000\n",
    "# print \"walk -\",len(rawWalkValues)\n",
    "# print \"sit -\",len(rawSittingValues)\n",
    "# print \"car -\",len(rawCarValues)\n",
    "# print \"jog -\",len(rawJogValues)\n",
    "# print \"stairs -\",len(rawStairsValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "So now that I've got my data loaded and in the correct format lets try some machine learning.\n",
    "At this point I'm doing a multi-classifier with all five data sets combined and using all 15 data fields, more on that later\n",
    "\n",
    "Since all of my data was 100MHZ and I had a 1000 records per 10 second chunk I only used the means of each field. I felt that with that much data it would probably work pretty good, which it does.  Instead of changing the aggregation calculation up I did some interesting ML things later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Where the Decision Tree Learning Happens\n",
    "# This is a multi-classifier for all five conditions \n",
    "from sklearn import tree\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "  \n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(allTrain, clsTrain)\n",
    "\n",
    "# Full disclosure - if you run this a few times you could get different output results each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for all test data: 0.933333333333\n",
      "Column Data Types\n",
      "['Walking', 'Sitting', 'Car', 'Jogging', 'Stairs']\n",
      "Walking: Score for walk test  1.0 \n",
      "[[1.000 0.000 0.000 0.000 0.000]\n",
      " [1.000 0.000 0.000 0.000 0.000]\n",
      " [1.000 0.000 0.000 0.000 0.000]\n",
      " [1.000 0.000 0.000 0.000 0.000]\n",
      " [1.000 0.000 0.000 0.000 0.000]\n",
      " [1.000 0.000 0.000 0.000 0.000]]\n",
      "Sitting: Score for sit test  1.0 \n",
      "[[0.000 1.000 0.000 0.000 0.000]\n",
      " [0.000 1.000 0.000 0.000 0.000]\n",
      " [0.000 1.000 0.000 0.000 0.000]\n",
      " [0.000 1.000 0.000 0.000 0.000]\n",
      " [0.000 1.000 0.000 0.000 0.000]\n",
      " [0.000 1.000 0.000 0.000 0.000]]\n",
      "Car drive: Score for car test  1.0 \n",
      "[[0.000 0.000 1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000 0.000 0.000]]\n",
      "Jogging: Score for jog test  0.666666666667 \n",
      "[[0.000 0.000 0.000 1.000 0.000]\n",
      " [1.000 0.000 0.000 0.000 0.000]\n",
      " [0.000 0.000 0.000 1.000 0.000]\n",
      " [0.000 0.000 0.000 1.000 0.000]\n",
      " [0.000 0.000 0.000 1.000 0.000]\n",
      " [1.000 0.000 0.000 0.000 0.000]]\n",
      "Stairs: Score for stairs test  1.0 \n",
      "[[0.000 0.000 0.000 0.000 1.000]\n",
      " [0.000 0.000 0.000 0.000 1.000]\n",
      " [0.000 0.000 0.000 0.000 1.000]\n",
      " [0.000 0.000 0.000 0.000 1.000]\n",
      " [0.000 0.000 0.000 0.000 1.000]\n",
      " [0.000 0.000 0.000 0.000 1.000]]\n"
     ]
    }
   ],
   "source": [
    "# the results for the Decision Tree learning\n",
    "print \"Score for all test data:\",clf.score(allTest, clsTest)\n",
    "# In multi-label classification, this is the subset accuracy which is a harsh metric since you require for \n",
    "# each sample that each label set be correctly predicted.\n",
    "\n",
    "# print \"Score for Sit test data:\",clf.score(sitTest, [1,1,1,1,1,1])\n",
    "\n",
    "# clf.predict(walkTest) # the walkTest is interesting because it sometimes gets sitting, but mostly finds walking\n",
    "clfwalkResults = clf.predict_proba(walkTest)\n",
    "clfsitResults = clf.predict_proba(sitTest)\n",
    "clfcarResults =  clf.predict_proba(carTest)\n",
    "clfjogResults =  clf.predict_proba(jogTest)\n",
    "clfstairsResults =  clf.predict_proba(stairsTest)\n",
    "\n",
    "print \"Column Data Types\"\n",
    "print dataType.values()\n",
    "print \"Walking: Score for walk test \",clf.score(walkTest, [0,0,0,0,0,0]),\"\\n\", clfwalkResults\n",
    "print \"Sitting: Score for sit test \",clf.score(sitTest, [1,1,1,1,1,1]),\"\\n\", clfsitResults\n",
    "print \"Car drive: Score for car test \",clf.score(carTest, [2,2,2,2,2,2]),\"\\n\", clfcarResults\n",
    "print \"Jogging: Score for jog test \",clf.score(jogTest, [3,3,3,3,3,3]),\"\\n\", clfjogResults\n",
    "print \"Stairs: Score for stairs test \",clf.score(stairsTest, [4,4,4,4,4,4]),\"\\n\", clfstairsResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, penalty='l2',\n",
       "          random_state=None, tol=0.0001)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression ML\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "logistic.fit(allTrain, clsTrain)\n",
    "# LogisticRegression(C=100000.0, class_weight=None, dual=False,fit_intercept=True, intercept_scaling=1,\n",
    "#                     penalty='l2', random_state=None, tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for all test data: 1.0\n",
      "Column Data Types\n",
      "['Walking', 'Sitting', 'Car', 'Jogging', 'Stairs']\n",
      "Walking: Score for walk test  1.0 \n",
      "[[1.000 0.000 0.000 0.000 0.000]\n",
      " [1.000 0.000 0.000 0.000 0.000]\n",
      " [1.000 0.000 0.000 0.000 0.000]\n",
      " [1.000 0.000 0.000 0.000 0.000]\n",
      " [1.000 0.000 0.000 0.000 0.000]\n",
      " [1.000 0.000 0.000 0.000 0.000]]\n",
      "Sitting: Score for sit test  1.0 \n",
      "[[0.000 1.000 0.000 0.000 0.000]\n",
      " [0.000 1.000 0.000 0.000 0.000]\n",
      " [0.000 1.000 0.000 0.000 0.000]\n",
      " [0.000 1.000 0.000 0.000 0.000]\n",
      " [0.000 1.000 0.000 0.000 0.000]\n",
      " [0.000 1.000 0.000 0.000 0.000]]\n",
      "Car drive: Score for car test  1.0 \n",
      "[[0.000 0.000 1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000 0.000 0.000]\n",
      " [0.012 0.000 0.982 0.000 0.005]]\n",
      "Jogging: Score for jog test  1.0 \n",
      "[[0.000 0.000 0.000 1.000 0.000]\n",
      " [0.000 0.000 0.000 1.000 0.000]\n",
      " [0.000 0.000 0.000 1.000 0.000]\n",
      " [0.000 0.000 0.000 1.000 0.000]\n",
      " [0.000 0.000 0.000 1.000 0.000]\n",
      " [0.000 0.000 0.000 1.000 0.000]]\n",
      "Stairs: Score for stairs test  1.0 \n",
      "[[0.000 0.000 0.000 0.000 1.000]\n",
      " [0.000 0.000 0.000 0.000 1.000]\n",
      " [0.000 0.000 0.000 0.000 1.000]\n",
      " [0.000 0.000 0.000 0.000 1.000]\n",
      " [0.000 0.000 0.000 0.000 1.000]\n",
      " [0.000 0.000 0.000 0.000 1.000]]\n"
     ]
    }
   ],
   "source": [
    "# logistic.predict(walkTest)\n",
    "# logistic.predict(sitTest)\n",
    "# logistic.predict(carTest)\n",
    "# logistic.predict(jogTest)\n",
    "# logistic.predict(stairsTest)\n",
    "# logistic.predict_proba(stairsTest)\n",
    "\n",
    "logwalkResults = logistic.predict_proba(walkTest)\n",
    "logsitResults = logistic.predict_proba(sitTest)\n",
    "logcarResults =  logistic.predict_proba(carTest)\n",
    "logjogResults =  logistic.predict_proba(jogTest)\n",
    "logstairsResults =  logistic.predict_proba(stairsTest)\n",
    "\n",
    "print \"Score for all test data:\",logistic.score(allTest, clsTest)\n",
    "# In multi-label classification, this is the subset accuracy which is a harsh metric since you require for \n",
    "# each sample that each label set be correctly predicted.\n",
    "\n",
    "print \"Column Data Types\"\n",
    "print dataType.values()\n",
    "print \"Walking: Score for walk test \",logistic.score(walkTest, [0,0,0,0,0,0]),\"\\n\", logwalkResults\n",
    "print \"Sitting: Score for sit test \",logistic.score(sitTest, [1,1,1,1,1,1]),\"\\n\", logsitResults\n",
    "print \"Car drive: Score for car test \",logistic.score(carTest, [2,2,2,2,2,2]),\"\\n\", logcarResults\n",
    "print \"Jogging: Score for jog test \",logistic.score(jogTest, [3,3,3,3,3,3]),\"\\n\", logjogResults\n",
    "print \"Stairs: Score for stairs test \",logistic.score(stairsTest, [4,4,4,4,4,4]),\"\\n\", logstairsResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Machine Learning with Support Vector Machines\n",
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear')\n",
    "svc.fit(allTrain, clsTrain)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for all test data: 1.0\n",
      "Walking: Score for walk test  1.0 :Results  [0 0 0 0 0 0]\n",
      "Sitting: Score for sit test  1.0 :Results  [1 1 1 1 1 1]\n",
      "Car drive: Score for car test  1.0 :Results  [2 2 2 2 2 2]\n",
      "Jogging: Score for jog test  1.0 :Results  [3 3 3 3 3 3]\n",
      "Stairs: Score for stairs test  1.0 :Results  [4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "# Machine learning Output\n",
    "\n",
    "svcwalkResults = svc.predict(walkTest)\n",
    "svcsitResults = svc.predict(sitTest)\n",
    "svccarResults =  svc.predict(carTest)\n",
    "svcjogResults =  svc.predict(jogTest)\n",
    "svcstairsResults =  svc.predict(stairsTest)\n",
    "\n",
    "print \"Score for all test data:\",svc.score(allTest, clsTest)\n",
    "# In multi-label classification, this is the subset accuracy which is a harsh metric since you require for \n",
    "# each sample that each label set be correctly predicted.\n",
    "\n",
    "# print \"Column Data Types\"\n",
    "# print dataType.values()\n",
    "print \"Walking: Score for walk test \",svc.score(walkTest, [0,0,0,0,0,0]),\":Results \", svcwalkResults\n",
    "print \"Sitting: Score for sit test \",svc.score(sitTest, [1,1,1,1,1,1]),\":Results \", svcsitResults\n",
    "print \"Car drive: Score for car test \",svc.score(carTest, [2,2,2,2,2,2]),\":Results \", svccarResults\n",
    "print \"Jogging: Score for jog test \",svc.score(jogTest, [3,3,3,3,3,3]),\":Results \", svcjogResults\n",
    "print \"Stairs: Score for stairs test \",svc.score(stairsTest, [4,4,4,4,4,4]),\":Results \", svcstairsResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see my machine learning works pretty good, but at this point I'm just feeding the algorithms all 15 fields from my data set and taking the mean.  I wonder how it would change if I instead just used the most relevant fields.\n",
    "\n",
    "To find those fields I can do one of these:\n",
    "1) Manually try every field in the set one at a time (or groups of N, ugh)\n",
    "2) Visually plot the information and look for what fields I should use\n",
    "3) Use Feature Selection, aka machine learning to find the most informative fields in the data\n",
    "\n",
    "1 would work but just plain feels wrong given better methods.  I did do some of 2 and mapping the lines suggested using the acceleromter data, the x and z directions mostly.\n",
    "\n",
    "However I really wanted to put machine learning to work and do feature selection. So I started working my way through this page\n",
    "http://scikit-learn.org/stable/modules/feature_selection.html and began working my way down the methods on that page.\n",
    "\n",
    "The next few blocks cover what I found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The variance threshold eliminates fields (columns) of data what have a low variance, meaning they aren't informative\n",
    "# after trying I'm not a fan of this method, see comments below\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.8*(1-.8)))\n",
    "# print sel.fit_transform(allTrain)[0] # uncomment this to see results\n",
    "\n",
    "# So this strips out the low variance stuff but doesn't help me identify the right features, just removes certain features\n",
    "# I can do (and did) a manual compare but that just seems wrong for some reason, this ends up reducing down to just 9 columns\n",
    "# out of the original 15 - adjusting the variance threshold brings this up or down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# chi squared feature selection - which doesn't work for negative values, boo\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# X_new = SelectKBest(chi2, k=2).fit_transform(allTrain, clsTrain)\n",
    "# X_new.shape\n",
    "\n",
    "# This doesn't work for negative values which is what I have - so this selection is out\n",
    "# I could have normalized or shifted everything to be positive but other methods worked so I didn't bother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attitude_roll', 'attitude_pitch', 'attitude_yaw', 'rotation_rate_x', 'rotation_rate_y', 'rotation_rate_z', 'gravity_x', 'gravity_y', 'gravity_z', 'user_acc_x', 'user_acc_y', 'user_acc_z', 'magnetic_field_x', 'magnetic_field_y', 'magnetic_field_z']\n",
      "[False False False False False False False False False  True False  True\n",
      " False False False]\n",
      "[ 5  8 11  9 10  7  4  6  2  1  3  1 14 13 12]\n",
      "Two Most Important Features are:\n",
      "   --  user_acc_x\n",
      "   --  user_acc_z\n",
      "The Most Important Feature is:\n",
      "   --  user_acc_x\n"
     ]
    }
   ],
   "source": [
    "# This attempt uses recursive feature elimination to find the n most informative features\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html for details\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "selector = RFE(estimator,2,step=1) # select the n most informative features\n",
    "selector = selector.fit(allTrain, clsTrain) # the magic\n",
    "\n",
    "print Labels.values()\n",
    "print(selector.support_)\n",
    "print(selector.ranking_)\n",
    "print \"Two Most Important Features are:\"\n",
    "rank = selector.ranking_\n",
    "for i in range(len(rank)):\n",
    "    if rank[i] == 1:\n",
    "        print \"   -- \",Labels[i]\n",
    "        \n",
    "\n",
    "selector = RFE(estimator,1,step=1) # select the n most informative features\n",
    "selector = selector.fit(allTrain, clsTrain)\n",
    "print \"The Most Important Feature is:\"\n",
    "rank = selector.ranking_\n",
    "for i in range(len(rank)):\n",
    "    if rank[i] == 1:\n",
    "        print \"   -- \",Labels[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. feature 6 :gravity_x (0.152001)\n",
      "2. feature 13 :magnetic_field_y (0.112911)\n",
      "3. feature 7 :gravity_y (0.111488)\n",
      "4. feature 0 :attitude_roll (0.100986)\n",
      "5. feature 1 :attitude_pitch (0.099890)\n",
      "6. feature 8 :gravity_z (0.091448)\n",
      "7. feature 9 :user_acc_x (0.065058)\n",
      "8. feature 14 :magnetic_field_z (0.061473)\n",
      "9. feature 12 :magnetic_field_x (0.058675)\n",
      "10. feature 10 :user_acc_y (0.056254)\n",
      "11. feature 2 :attitude_yaw (0.035230)\n",
      "12. feature 4 :rotation_rate_y (0.019157)\n",
      "13. feature 5 :rotation_rate_z (0.015653)\n",
      "14. feature 11 :user_acc_z (0.013717)\n",
      "15. feature 3 :rotation_rate_x (0.006060)\n"
     ]
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAyAAAAJTCAYAAADwsXKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAPYQAAD2EBqD+naQAAIABJREFUeJzs3XtclWW+///3jRAnBQ9pgScKZcQxBVGjPFEec7KxwgMe\n",
       "2paieze7aaN7PPRNzR1l43bScWY3kzaiYIMajVP5MEsbzVRGDTDbBg/aY2IpZKUoIuDp/v3BsH6u\n",
       "FqAcvADX6/l4rIfjta7rvj43q6b15r6u+7Zs27YFAAAAAAZ4NHQBAAAAANwHAQQAAACAMQQQAAAA\n",
       "AMYQQAAAAAAYQwABAAAAYAwBBAAAAIAxBBAAAAAAxhBAAAAAABhDAAEAAABgDAEEAAAAgDEEEAAA\n",
       "AADGEEAAAAAAGEMAAQAAAGAMAQQAAACAMQQQAAAAAMYQQAAAAAAYQwABAAAAYAwBBAAAAIAxBBAA\n",
       "AAAAxhBAAAAAABhDAAEAAABgDAEEAAAAgDEEEAAAAADGEEAAAAAAGEMAAQAAAGAMAQQAAACAMQQQ\n",
       "AAAAAMYQQAAAAAAYQwABAAAAYAwBBAAAAIAxBBAAAAAAxhBAAAAAABhDAAEAAABgDAEEAAAAgDEE\n",
       "EAAAAADGEEAAAAAAGEMAAQAAAGAMAQQA4CImJkYeHvwnAgBQ//ivC4BbioeHR7WvdevWGa3lgQce\n",
       "MDZffbIsS5ZlNXQZN92uXbvk4eGhxYsXN3QpAOA2PBu6AACob5ZladGiRZW+FxkZabyWpig5OVkl\n",
       "JSUNXYYxTfVzAoCmiAAC4Ja0cOHChi6hSevYsWNDl2CUbdsNXQIAuA2WYAFwW6dPn9b8+fMVHh4u\n",
       "Pz8/tWzZUkOHDtX27dtd+p47d07//d//rQcffFAdOnSQt7e32rVrp5///Of6+9//7tR37dq1jv0T\n",
       "FUt8Kl4VS32ut/QnJCREd911V6XHXbdunbZt26aYmBgFBgY67dW4fPmyXnvtNUVHRysgIED+/v7q\n",
       "3bu3/ud//qdGX7Ir2wNybc2ffvqpRo4cqZYtW6pVq1Z6/PHH9fXXX0uS/vGPf2j8+PFq27at/Pz8\n",
       "9MADD+jw4cMuc0ydOlUeHh766quv9Oqrr6pbt27y9fVVx44dNWvWLBUVFVVaW0ZGhh5//HG1a9dO\n",
       "Pj4+CgkJ0S9+8QsVFBRUO8fvfvc79ezZ01HTk08+qQcffFCStHjxYqfPaffu3ZJq9rlXqFh698MP\n",
       "P2jGjBkKCgqSj4+PevToobVr11b5M//www81evRox3l16tRJY8aM0UcffeTS94MPPtCoUaN0++23\n",
       "y8fHR126dNGcOXN09uxZl76HDx9WXFycQkJC5OPjo3bt2ikqKkoJCQm6fPlylfUAwM3CFRAAbikv\n",
       "L08xMTHKy8vToEGDNGrUKJ0/f15btmzRyJEj9frrr2v69OmO/l988YWef/55DR48WKNHj1arVq2U\n",
       "l5end999V++//77ee+89jRgxQlL5Mq9FixZp8eLFCgkJ0dSpUx3HiYmJcaqjuqU/Vb2Xlpambdu2\n",
       "adSoUXr66aeVl5cnSbp06ZJGjx6tDz/8UN26ddPkyZPl4+Ojv/3tb3rmmWe0f/9+JScn3/DPqKr5\n",
       "Dx48qF//+teKiYnRjBkzdPjwYW3evFmff/65Nm/erEGDBumnP/2ppk6dqmPHjukvf/mLhg0bpqNH\n",
       "j8rf39/leP/xH/+hTz75ROPHj1fLli21bds2rVixQp988on27Nkjb29vR98tW7bo8ccfl2VZio2N\n",
       "VefOnfXpp5/qD3/4g9555x3t2bNHISEhLnM8++yz+uSTT/Twww/r4YcfVrNmzdSnTx9J0rp16xQT\n",
       "E+P02VQcoyaf+7UKCwvVv39/eXt7a9y4cSorK9OmTZv01FNPycPDQ0888YRT/0WLFunFF19UixYt\n",
       "NGbMGHXs2FEnTpzQvn379Oabb2rIkCGOvosXL9bixYvVpk0bR2D57LPPtGzZMm3dulXp6elq0aKF\n",
       "pPLwce+996pZs2Z65JFHdNddd+ncuXP68ssv9Yc//EEvvfSSPD35KgDAMBsAbiGWZdmWZdkvvPCC\n",
       "vWjRIqfX2rVrHf0GDx5sN2vWzN64caPT+MLCQjsiIsL29fW1v/32W0f72bNn7R9++MFlvm+++cYO\n",
       "Dg62w8PDK63lgQceqLTOnTt32pZl2YsXL670/c6dO9t33XWXU1tSUpJtWZbdrFkz+4MPPnAZs2jR\n",
       "ItuyLPuXv/ylffXqVUf7lStX7GnTptmWZdnvvPNOpfP92ODBg20PD49Ka7Ysy/7zn//s9F7F8QMD\n",
       "A+2XX37Z6b0XX3zRtizL/u1vf+vU/i//8i+2ZVl227Zt7ePHjzvar169aj/++OO2ZVn2iy++6Ggv\n",
       "KiqyW7dubXt6etp79uxxOtavf/1r27Ise/jw4ZXO0aFDB/vYsWMu53m9z6G2n7tlWXZ8fLzT5/DF\n",
       "F1/Ynp6edvfu3Z36f/DBB7ZlWXZoaKh98uTJSueq8Le//c22LMvu37+/ffbsWad+a9eutS3LshMS\n",
       "Ehxts2bNsi3Lst99912X4xYWFjrVBwCmEEAA3FIqvvxV9qoIA4cOHbIty7LHjRtX6TH++te/2pZl\n",
       "2a+99toNzfnMM8/YlmXZX3/9tUstNyOAPPbYYy79r1y5Yrdu3doODg62r1y54vL+mTNnbA8PjyrP\n",
       "+ceqCyCDBg1y6b97927bsiz77rvvdvlSm5eXZ1uWZT/11FNO7RXhIDEx0eV4R48etZs1a+b0M1i/\n",
       "fr1tWZY9adIkl/6XL1+2Q0JCbMuynMJMxRwrV66s9Dyv9zlUp7rPvXnz5nZRUZHLmEGDBtkeHh52\n",
       "cXGxo+3hhx+2Lcuy//rXv153zjFjxtiWZdlffPFFpe9HRETY7dq1c/y9IoB8+OGHN3paAHDTcd0V\n",
       "wC3HsixduXKlyvfT09MllS+TeeGFF1ze/+677yRJ2dnZTu179+7Vb3/7W6Wnp+u7777TxYsXnd4/\n",
       "ceKEOnToUMfqr69fv34ubbm5uTpz5oy6du2q//qv/6p0nI+Pj8s51UbF0qVrBQUFSZIiIiJclm4F\n",
       "BwdLkr755ptKjzd48GCXtrvuuksdOnRQXl6ezp07p4CAAGVmZkqSY9/GtZo1a6ZBgwYpJSVFWVlZ\n",
       "LpvoK/uZ3ajafO5du3ZV8+bNXY7VsWNH2batM2fOyM/PT5L097//XR4eHho5cuR1a0lPT5eXl5c2\n",
       "bdpU6Z6eixcv6rvvvtOZM2fUqlUrTZgwQStXrtSYMWMUGxurIUOGqH///goNDa3JjwAA6hUBBIDb\n",
       "+eGHHyRJ27dvr3TDuVQeYoqLix1/37x5s2JjY+Xn56dhw4YpNDRU/v7+8vDw0M6dO/Xxxx+rrKzM\n",
       "SP133nmnS1vFOX355ZdVBpAfn1NtBQYGurRV7COo7r1Lly5Verw77rij0vY777xTx48f19mzZxUQ\n",
       "EODYYF0Rdn6sor2yjdiV/cxuRG0/95YtW1Z6vIqfxbUBubCwUK1atXLa61KVH374QVeuXKn2uSWW\n",
       "Zen8+fNq1aqV+vbtq08++UQvvfSS0tLSlJKSIkn6yU9+okWLFmnChAnXnRMA6hsBBIDbqfiSvHLl\n",
       "Sv37v//7DY1ZsGCBfHx89Omnn+onP/mJ03snTpzQxx9/XKMaKu4wVdVdiAoLC9W6detK36tsc3jF\n",
       "OT322GNKS0urUS0N7dtvv1XXrl1d2gsKCmRZluPcKv6s7G5XkpSfn+/U71q1fc5HfX/ulWnZsqXO\n",
       "nDmj0tJS+fj4VNu34ty+//77Gz5+dHS03nvvPV26dEmffvqptm3bpt/97neaOHGi2rZt67TBHQBM\n",
       "4Da8ANzOfffdJ0mOW63eiP/7v/9T9+7dXb6EXr16VXv27Kl0THVLwVq1aiVJOn78eKVznTt37oZr\n",
       "k6Tw8HC1bNlS6enpTe7Wqrt27XJpO3r0qL7++muFhIQoICBAktS7d29J0s6dO136X758WZ988oks\n",
       "y3L0uxHNmjWTpCo/p9p87jV133336erVq9q2bdsN9T19+rS++OKLGs/j5eWl++67T4sXL9bKlSsl\n",
       "Se+++26NjwMAdUUAAeB2oqKiNHDgQP3lL39RUlJSpX0+//xzx14QqXxPQm5uruO37FL5w+teeOEF\n",
       "ZWdnV/ob9jZt2jiejfFj4eHhCggI0DvvvOM0T0lJiX75y1/W+JyaNWumZ555Rvn5+frlL3+p0tJS\n",
       "lz75+fn1sgekvv32t791CmJXr17Vr371K9m2rSeffNLRPmbMGLVu3Vqpqanav3+/0zFWrFihY8eO\n",
       "aejQoTXah9OmTRtJctzK+Mdq87nX1DPPPCNJmj17tk6ePOny/rVtCQkJkqT4+HinmioUFxc7PZ9k\n",
       "3759lf6zUHEVqWIfCgCY5JZLsMrKyrRw4UKlpKSosLBQPXv2VGJiooYOHVrtuN27d2vZsmU6dOiQ\n",
       "vvvuOwUEBKhHjx76z//8Tz300ENOfWNiYir97eqIESP0/vvv1+v5AKi5P//5z3rwwQc1bdo0rVy5\n",
       "Uv369VPLli31zTff6PDhwzpy5Ij+/ve/q23btpLKv/j967/+qyIjI/XYY4/Jy8tLe/fuVXZ2tkaP\n",
       "Hq333nvPZY6hQ4dqw4YNeuSRRxQZGSkvLy8NHjxYAwcOlKenp5599lm9+OKLioyM1JgxY3T58mXt\n",
       "2LFD7du3V3BwcI2fzr1gwQJ99tln+uMf/6j33ntPDzzwgNq3b69Tp07pyy+/1L59+/Tyyy8rPDz8\n",
       "ho5X0/lra8CAAYqIiND48eMVEBCgDz74QIcPH1afPn00Z84cRz9/f3+tWbNGY8eO1eDBgzV27Fh1\n",
       "7NhRGRkZ2r59u4KCgvT666/XaO5u3bqpffv22rBhg7y8vNSpUydZlqUnnnhCnTp1qtXnXlPDhg3T\n",
       "888/r8TERIWHh2vMmDHq0KGDvv32W+3Zs0f33XefIyg/+OCDeuWVVzR//nx17dpVo0aNUkhIiM6f\n",
       "P6+8vDzt3r1bAwcO1NatWyVJS5cu1c6dOzVw4ECFhISoefPmOnLkiLZt26bWrVtrxowZda4fAGqs\n",
       "Ae/A1WAmTJhge3l52XPmzLFXr15t33///baXl5fLfeV/7I033rAfffRR++WXX7bXrFljL1u2zI6I\n",
       "iLAty7LXr1/v1Hfw4MF2p06d7DfffNPptXPnzpt4ZgAsy3K5fWxVioqK7JdfftmOioqymzdvbvv6\n",
       "+tp33323/fDDD9urV692ulWqbZc/ZyEiIsL29/e327Ztaz/22GP2//7v/9ovvPCC7eHhYX/88cdO\n",
       "/U+dOmVPnDjRvuOOO+xmzZrZHh4eLrd7feWVV+zQ0FD7tttuszt37mzPnTvXvnDhgh0SEuJyG961\n",
       "a9faHh4e9rp166o9r5SUFHvIkCF269at7dtuu83u0KGDPXDgQHvJkiVOz5SoTkxMTJW34a3slrVf\n",
       "ffWVbVmW/eSTT1Z6vMpuSVxxi9yvvvrK/s1vfmN369bN9vHxsTt06GAnJCRUehtb27btgwcP2o8+\n",
       "+qjdtm1bx8/t6aeftvPz8136Tp061fbw8LDz8vKqPNeDBw/aQ4YMsQMDA20PDw+Xz7Kmn3t1t1+u\n",
       "rp6tW7faI0eOtFu3bm17e3vbnTp1sh977LFK/7uxZ88ee9y4cXZwcLB922232e3atbMjIyPt2bNn\n",
       "2xkZGY5+H374of3kk0/a3bt3twMDA21/f3+7W7du9rPPPut0u2IAMMmybUO/4mokDhw4oOjoaC1b\n",
       "tkyzZs2SVH5FpEePHmrXrp327t1bo+OVlJTo7rvvVlhYmNNmxJiYGJ0+fVqHDx+u1/oB4FYxdepU\n",
       "JScn69ixY+rUqVNDlwMAMMTt9oCkpaXJ09PT6bKzt7e3pk2bpvT0dJ04caJGx/P19dXtt98uLy8v\n",
       "l/ds29aVK1d0/vz5OtcNAAAA3ArcLoBkZWUpLCzM5QFRffv2lSQdOnTousc4d+6cvv/+e+Xk5Oi5\n",
       "555Tbm6uZs+e7dIvNzdX/v7+CggIUFBQkBYuXNjk7k4DAAAA1Ce324Sen59f6UOsKtoquwPJj40b\n",
       "N04ffvihpPJNkZs2bXLZhN6lSxcNGTJE99xzj4qLi/XWW28pMTFRubm52rBhQz2cCQA0bZZl1ctd\n",
       "pAAATYvb7QEJDQ1VeHi4tmzZ4tR+9OhRdenSRStWrLjuLTA/++wzff/99zp+/Lj++Mc/6vDhw3r3\n",
       "3Xc1bNiwasfNnDlTq1evVnp6uu699946nwsAAADQ1LjdEixfX1+VlZW5tFfcJ93X1/e6x+jVq5eG\n",
       "DBmiJ598Unv27FGXLl30i1/84rrjKpZpffTRR5W+f+HCBWVmZurChQvXPRYAAADM4/ta3bndEqyg\n",
       "oKBKl1lVPNApODi4Rsfz8vLS6NGj9corr6iwsFAtW7assm/Fw7FOnz5d6ftZWVkaMGCAIiMj1aJF\n",
       "C6f3RowYoZEjR9aoNgAAANTetm3b9MEHHzi1FRUVKSsrS3v27FH//v0bqLKmze0CSGRkpHbt2qWi\n",
       "oiKnL/kVT9WNiIio8TFLSkokSR4e1V9QOnr0qCQ5Hmz2Y8eOHZNUHkR+bPfu3fp//+//1bg2AAAA\n",
       "1L9jx44RQGrJ7QJIbGysli1bplWrVjmWRJWVlSkpKUnR0dFq3769JKmgoECFhYXq0qWLPD3Lf0yn\n",
       "Tp1Su3btnI5XWFiot99+W/fcc48CAgIklSfj2267Td7e3o5+tm0rMTFRlmVpxIgRldYWEhIiSVq/\n",
       "fv0NP6nYpISEBC1fvryhy6hUY62tsdYlUVttNdbaGmtdErXVVmOtrbHWJVFbbTXW2hprXdnZ2Zo8\n",
       "ebLjextqzu0CSL9+/TR27FjNnz9fp06dUmhoqNatW6fjx48rKSnJ0W/evHkuD8h66KGH1LFjR/Xr\n",
       "10/t2rVzjPnuu++0du1ax9iMjAzFxcVp4sSJCg0NVUlJiTZv3qx9+/Zp5syZVV5lqdh/Eh4ert69\n",
       "e9+8H0ItBQYGNsq6pMZbW2OtS6K22mqstTXWuiRqq63GWltjrUuittpqrLU11roq3Mi+YVTO7QKI\n",
       "JCUnJ2vBggVKSUnRmTNn1KtXL23ZskUDBgxw9Kns9pDTpk3Thg0btGLFChUWFqpNmzYaMGCA5s+f\n",
       "7/QvSEhIiAYNGqTNmzeroKBAHh4e6t69u15//XXFx8cbO08AAACgsXHLAOLt7a2lS5dq6dKlVfZJ\n",
       "SkpyuiIiSU8//bSefvrp6x4/JCREGzdurHOdAAAAwK3G7W7DCwAAAKDhEEBww+Li4hq6hCo11toa\n",
       "a10StdVWY62tsdYlUVttNdbaGmtdErXVVmOtrbHWhbpzuyehN2aZmZmKiopSRkZGo950BQAA4K74\n",
       "vlZ3XAEBAAAAYAwBBAAAAIAxBBAAAAAAxhBAAAAAABhDAAEAAABgDAEEAAAAgDEEEAAAAADGEEAA\n",
       "AAAAGEMAAQAAAGAMAQQAAACAMQQQAAAAAMYQQAAAAAAYQwABAAAAYAwBBAAAAIAxBBAAAAAAxhBA\n",
       "AAAAABhDAAEAAABgDAEEAAAAgDEEEAAAAADGEEAAAAAAGEMAAQAAAGAMAQQAAACAMQQQAAAAAMYQ\n",
       "QAAAAAAYQwABAAAAYAwBBAAAAIAxBBAAAAAAxhBAAAAAABhDAAEAAABgDAEEAAAAgDEEEAAAAADG\n",
       "EEAAAAAAGEMAAQAAAGAMAQQAAACAMQQQAAAAAMYQQAAAAAAYQwABAAAAYAwBBAAAAIAxBBAAAAAA\n",
       "xhBAAAAAABhDAAEAAABgDAEEAAAAgDEEEAAAAADGuGUAKSsr09y5cxUcHCw/Pz9FR0drx44d1x23\n",
       "e/duPfLII+rUqZN8fX11xx13aMiQIXr//fcr7b9v3z4NGDBA/v7+CgoK0rPPPqvi4uL6Ph0AAACg\n",
       "yXDLADJ16lQtX75cU6ZM0cqVK9WsWTONGjVKe/furXbcl19+KU9PT/3bv/2bXnvtNc2ZM0enT5/W\n",
       "z372M7355ptOfQ8dOqQhQ4aotLRUy5cv1/Tp07Vq1SqNHTv2Zp4aAAAA0KhZtm3bDV2ESQcOHFB0\n",
       "dLSWLVumWbNmSSq/ItKjRw+1a9fuuiHkx0pKSnT33XcrLCxMH3/8saN91KhROnz4sHJyctS8eXNJ\n",
       "0p/+9CfFx8frgw8+0LBhw1yOlZmZqaioKGVkZKh37951OMv6kZpa/pKk0lIpL0/q3Fny8Slvi4sr\n",
       "fwEAALiLxvZ9rSlyuysgaWlp8vT01IwZMxxt3t7emjZtmtLT03XixIkaHc/X11e33367vLy8HG3n\n",
       "zp3Tjh07NHnyZEf4kKQnnnhCzZs316ZNm+p+IgbExUnvvlv+euUVKTe3/M+KNsIHAAAAasqzoQsw\n",
       "LSsrS2FhYU7BQJL69u0rqXzpVPv27as9xrlz53Tx4kV9//33Sk5OVm5urpYuXep4//PPP9fly5fV\n",
       "p08fp3FeXl6KiIhQVlZWPZ0NAAAA0LS4XQDJz89XUFCQS3tF28mTJ697jHHjxunDDz+UJPn7+2vT\n",
       "pk166KGHnOa49pjXuvPOO7Vnz55a1Q4AAAA0dW63BKukpETe3t4u7T7/3NhQUlJy3WP8+te/1vbt\n",
       "2/WnP/1J3bt314QJE7R9+3anOSRVOc+NzAEAAADcitzuCoivr6/Kyspc2ktLSx3vX0+vXr0c/3vy\n",
       "5Mnq3bu3fvGLXyg3N9fpGFXN4+fnV6vaAQAAgKbO7QJIUFBQpcusKpZNBQcH1+h4Xl5eGj16tF55\n",
       "5RUVFhaqZcuWjqVXFcf88TzXmyMhIUGBgYFObXFxcYpj1zcAAIAxqampSq24Jeg/nT17toGquXW4\n",
       "XQCJjIzUrl27VFRUpBYtWjja9+/fL0mKiIio8TErllR5eJSvaOvRo4c8PT118OBBxcbGOvpdvHhR\n",
       "hw4d0oQJE6o93vLly7mtGwAAQAOr7BfAFbfhRe253R6Q2NhYXblyRatWrXK0lZWVKSkpSdHR0Y47\n",
       "YBUUFCgnJ0eXL1929Dt16pTL8QoLC/X222/rnnvuUUBAgCQpMDBQQ4cO1fr163X+/HlH35SUFBUX\n",
       "F/MwQgAAALgtt7sC0q9fP40dO1bz58/XqVOnFBoaqnXr1un48eNKSkpy9Js3b56Sk5N17NgxderU\n",
       "SZL00EMPqWPHjurXr5/atWvnGPPdd99p7dq1TvO89NJLuv/++zV48GDFx8frm2++0auvvqoRI0Zo\n",
       "+PDhJk8ZAAAAaDTcLoBIUnJyshYsWKCUlBSdOXNGvXr10pYtWzRgwABHH8uyZFmW07hp06Zpw4YN\n",
       "WrFihQoLC9WmTRsNGDBA8+fPd1kyFRkZqR07dmju3LmaNWuWAgICNH36dC1ZssTIOQIAAACNkWXb\n",
       "tt3QRaBcxZrCjIyMRrcHJDNTioqSMjKkRlYaAACAMY35+1pT4XZ7QAAAAAA0HAIIAAAAAGMIIAAA\n",
       "AACMIYAAAAAAMIYAAgAAAMAYAggAAAAAYwggAAAAAIwhgAAAAAAwhgACAAAAwBgCCAAAAABjCCAA\n",
       "AAAAjCGAAAAAADCGAAIAAADAGAIIAAAAAGMIIAAAAACMIYAAAAAAMIYAAgAAAMAYAggAAAAAYwgg\n",
       "AAAAAIwhgAAAAAAwhgACAAAAwBgCCAAAAABjCCAAAAAAjCGAAAAAADCGAAIAAADAGAIIAAAAAGMI\n",
       "IAAAAACMIYAAAAAAMIYAAgAAAMAYAggAAAAAYwggAAAAAIwhgAAAAAAwhgACAAAAwBgCCAAAAABj\n",
       "CCAAAAAAjCGAAAAAADCGAAIAAADAGAIIAAAAAGMIIAAAAACMIYAAAAAAMIYAAgAAAMAYAggAAAAA\n",
       "YwggAAAAAIwhgAAAAAAwhgACAAAAwBi3DCBlZWWaO3eugoOD5efnp+joaO3YseO64z766CM99dRT\n",
       "CgsLk7+/v0JDQxUfH6+CggKXvjExMfLw8HB5PfTQQzfjlAAAAIAmwbOhC2gIU6dO1dtvv62EhAR1\n",
       "7dpVSUlJGjVqlHbu3Kn+/ftXOW7u3LkqLCzU2LFj1bVrV/3jH//Q73//e23ZskWHDh3SHXfc4dS/\n",
       "Y8eOWrJkiVNbcHDwTTknAAAAoClwuwBy4MABbdy4UcuWLdOsWbMkSVOmTFGPHj00Z84c7d27t8qx\n",
       "K1as0IABA5zaRo4cqcGDB+v3v/+9XnzxRaf3AgMDNXHixPo/CQAAAKCJcrslWGlpafL09NSMGTMc\n",
       "bd7e3po2bZrS09N14sSJKsf+OHxI0sCBA9W6dWvl5OS4vGfbtq5cuaLz58/XT/EAAABAE+d2ASQr\n",
       "K0thYWFq3ry5U3vfvn0lSYcOHarR8c6fP6+ioiLdfvvtLu/l5ubK399fAQEBCgoK0sKFC3X58uXa\n",
       "Fw8AAAA0cW63BCs/P19BQUEu7RVtJ0+erNHxVqxYoUuXLmn8+PFO7V26dNGQIUN0zz33qLi4WG+9\n",
       "9ZYSExOVm5urDRs21P4EAAAAgCbM7QJISUmJvL29Xdp9fHwc79+o3bt3a/HixRo/frxiYmKc3nvj\n",
       "jTec/j5p0iTNnDlTq1evVkJCgu69996aFw8AAAA0cW63BMvX11dlZWUu7aWlpY73b0ROTo4effRR\n",
       "9ezZ0yVsVGX27NmSym/nCwAAALgjt7sCEhQUVOkyq/z8fEk3dpvcr7/+WsOHD1erVq20detW+fv7\n",
       "39DcHTp0kCSdPn262n4JCQkKDAx0aouLi1NcXNwNzQMAAIC6S01NVWpqqlPb2bNnG6iaW4fbBZDI\n",
       "yEjt2rVLRUVFatGihaN9//79kqSIiIhqx//www8aPny4Ll26pJ07d7o8+6M6R48elSS1bdu22n7L\n",
       "ly9X7969b/i4AAAAqH+V/QI4MzNTUVFRDVTRrcHtlmDFxsbqypUrWrVqlaOtrKxMSUlJio6OVvv2\n",
       "7SVJBQUFysnJcbprVXFxsUaNGqX8/Hxt3bpVoaGhlc5RVFTksszLtm0lJibKsiyNGDHiJpwZAAAA\n",
       "0Pi53RWQfv36aezYsZo/f75OnTql0NBQrVu3TsePH1dSUpKj37x585ScnKxjx46pU6dOkso3kh88\n",
       "eFBPPfWUjhw5oiNHjjj6t2jRQj//+c8lSRkZGYqLi9PEiRMVGhqqkpISbd68Wfv27dPMmTOve5UF\n",
       "AAAAuFWELomJAAAgAElEQVS5XQCRpOTkZC1YsEApKSk6c+aMevXqpS1btjg9aNCyLFmW5TTus88+\n",
       "k2VZWrNmjdasWeP0XkhIiCOAhISEaNCgQdq8ebMKCgrk4eGh7t276/XXX1d8fPzNP0EAAACgkbJs\n",
       "27YbugiUq1hTmJGR0ej2gGRmSlFRUkaG1MhKAwAAMKYxf19rKtxuDwgAAACAhkMAAQAAAGAMAQQA\n",
       "AACAMQQQAAAAAMYQQAAAAAAYQwABAAAAYAwBBAAAAIAxbvkgQuBmSU0tf0lSaamUlyd17iz5+JS3\n",
       "xcWVvwAAANwVAQSoR9cGjIqHN6am8vBGAACACizBAgAAAGAMAQQAAACAMQQQAAAAAMYQQAAAAAAY\n",
       "wyZ0NEncbQoAAKBpIoCgSeJuUwAAAE0TS7AAAAAAGEMAAQAAAGAMAQQAAACAMewBAdDguKkAAADu\n",
       "gwACoMFxUwEAANwHS7AAAAAAGEMAAQAAAGAMAQQAAACAMQQQAAAAAMYQQAAAAAAYQwABAAAAYAwB\n",
       "BAAAAIAxBBAAAAAAxhBAAAAAABhDAAEAAABgDAEEAAAAgDEEEAAAAADGEEAAAAAAGOPZ0AUAMCM1\n",
       "tfwlSaWlUl6e1Lmz5ONT3hYXV/4CAAC4mQgggJu4NmBkZkpRUeWBpHfvhq0LAAC4F5ZgAQAAADCG\n",
       "AAIAAADAGAIIAAAAAGMIIAAAAACMIYAAAAAAMIYAAgAAAMAYbsMLANXg+SkAANQvAggAVIPnpwAA\n",
       "UL9YggUAAADAGAIIAAAAAGMIIAAAAACMccsAUlZWprlz5yo4OFh+fn6Kjo7Wjh07rjvuo48+0lNP\n",
       "PaWwsDD5+/srNDRU8fHxKigoqLT/vn37NGDAAPn7+ysoKEjPPvusiouL6/t0AAAAgCbDLQPI1KlT\n",
       "tXz5ck2ZMkUrV65Us2bNNGrUKO3du7facXPnztXu3bv1+OOP63e/+50mTJigTZs2KTIyUt9++61T\n",
       "30OHDmnIkCEqLS3V8uXLNX36dK1atUpjx469macGAAAANGpudxesAwcOaOPGjVq2bJlmzZolSZoy\n",
       "ZYp69OihOXPmVBtCVqxYoQEDBji1jRw5UoMHD9bvf/97vfjii4725557Tm3atNGuXbvUvHlzSVJI\n",
       "SIji4+O1fft2DRs27CacHQAAANC4ud0VkLS0NHl6emrGjBmONm9vb02bNk3p6ek6ceJElWN/HD4k\n",
       "aeDAgWrdurVycnIcbefOndOOHTs0efJkR/iQpCeeeELNmzfXpk2b6ulsAAAAgKbF7QJIVlaWwsLC\n",
       "nIKBJPXt21dS+dKpmjh//ryKiop0++23O9o+//xzXb58WX369HHq6+XlpYiICGVlZdWyegAAAKBp\n",
       "c7sAkp+fr6CgIJf2iraTJ0/W6HgrVqzQpUuXNH78eKc5rj3mte68884azwEAAADcKtwugJSUlMjb\n",
       "29ul3cfHx/H+jdq9e7cWL16s8ePHKyYmxmkOSVXOU5M5AAAAgFuJ2wUQX19flZWVubSXlpY63r8R\n",
       "OTk5evTRR9WzZ0+98cYbLnNIqnIePz+/mpYNAAAA3BLc7i5YQUFBlS6Bqlg2FRwcfN1jfP311xo+\n",
       "fLhatWqlrVu3yt/f32WOa4/543muN0dCQoICAwOd2uLi4hQXF3fd2gAAAFA/UlNTlZqa6tR29uzZ\n",
       "Bqrm1uF2ASQyMlK7du1SUVGRWrRo4Wjfv3+/JCkiIqLa8T/88IOGDx+uS5cuaefOnbrjjjtc+vTo\n",
       "0UOenp46ePCgYmNjHe0XL17UoUOHNGHChGrnWL58uXr37l2T0wIAAEA9q+wXwJmZmYqKimqgim4N\n",
       "brcEKzY2VleuXNGqVascbWVlZUpKSlJ0dLTat28vSSooKFBOTo4uX77s6FdcXKxRo0YpPz9fW7du\n",
       "VWhoaKVzBAYGaujQoVq/fr3Onz/vaE9JSVFxcTEPIwQAAIDbcrsrIP369dPYsWM1f/58nTp1SqGh\n",
       "oVq3bp2OHz+upKQkR7958+YpOTlZx44dU6dOnSRJkyZN0sGDB/XUU0/pyJEjOnLkiKN/ixYt9POf\n",
       "/9zx95deekn333+/Bg8erPj4eH3zzTd69dVXNWLECA0fPtzcCQMAAACNiNsFEElKTk7WggULlJKS\n",
       "ojNnzqhXr17asmWL04MGLcuSZVlO4z777DNZlqU1a9ZozZo1Tu+FhIQ4BZDIyEjt2LFDc+fO1axZ\n",
       "sxQQEKDp06dryZIlN/fkAAAAgEbMLQOIt7e3li5dqqVLl1bZJykpyemKiCR99dVXNZqnf//+2rNn\n",
       "T61qBAAAAG5FbrcHBAAAAEDDIYAAAAAAMIYAAgAAAMAYAggAAAAAYwggAAAAAIwhgAAAAAAwhgAC\n",
       "AAAAwBgCCAAAAABjCCAAAAAAjCGAAAAAADCGAAIAAADAGAIIAAAAAGMIIAAAAACMIYAAAAAAMIYA\n",
       "AgAAAMAYAggAAAAAYwggAAAAAIwhgAAAAAAwhgACAAAAwBgCCAAAAABjCCAAAAAAjCGAAAAAADCG\n",
       "AAIAAADAGAIIAAAAAGMIIAAAAACMIYAAAAAAMIYAAgAAAMAYAggAAAAAYwggAAAAAIwhgAAAAAAw\n",
       "hgACAAAAwBgCCAAAAABjCCAAAAAAjCGAAAAAADCGAAIAAADAGAIIAAAAAGMIIAAAAACMIYAAAAAA\n",
       "MIYAAgAAAMAYAggAAAAAYwggAAAAAIwhgAAAAAAwhgACAAAAwBgCCAAAAABjCCAAAAAAjHHLAFJW\n",
       "Vqa5c+cqODhYfn5+io6O1o4dO647rqCgQPPmzdMDDzygFi1ayMPDQx9//HGlfWNiYuTh4eHyeuih\n",
       "h+r7dACgUUlNlR55pPw1fLj0k5+U/1nRlpra0BUCABqSZ0MX0BCmTp2qt99+WwkJCeratauSkpI0\n",
       "atQo7dy5U/37969yXE5OjpYuXaqwsDD17NlT6enpsiyryv4dO3bUkiVLnNqCg4Pr7TwAuK/U1P//\n",
       "i3xpqZSXJ3XuLPn4lLfFxZW/GsK1c2dmSlFR5bX27t0w9QAAGhe3CyAHDhzQxo0btWzZMs2aNUuS\n",
       "NGXKFPXo0UNz5szR3r17qxzbp08fnT59Wi1btlRaWprS09OrnSswMFATJ06s1/oBQOJLPgCg6XK7\n",
       "AJKWliZPT0/NmDHD0ebt7a1p06bpueee04kTJ9S+fftKxzZv3rxGc9m2rStXrqikpKTGYwEA9a8x\n",
       "XzkCAHfhdgEkKytLYWFhLoGgb9++kqRDhw5VGUBqKjc3V/7+/rp48aLuuOMOxcfHa+HChfL0dLsf\n",
       "OwA0Clw5AoCG53bfhPPz8xUUFOTSXtF28uTJepmnS5cuGjJkiO655x4VFxfrrbfeUmJionJzc7Vh\n",
       "w4Z6maMmLly4oJycnFqPz872lRSu7OxsSSW1Oka3bt3k5+dX6xoAAADQ9LldACkpKZG3t7dLu88/\n",
       "r7+XlNTuy/WPvfHGG05/nzRpkmbOnKnVq1crISFB9957b73Mc6NycnIUFRVVhyNESsrU5MmTJGXV\n",
       "6ggZGRnqza8ZAQAA3JrbBRBfX1+VlZW5tJeWljrev1lmz56t1atX66OPPjIeQCqslxRei3HZkibX\n",
       "cnzFWAAAAMDtAkhQUFCly6zy8/Ml3dzb5Hbo0EGSdPr06Zs2x/WES6rLNYi6jgcAAIB7c7sAEhkZ\n",
       "qV27dqmoqEgtWrRwtO/fv1+SFBERcdPmPnr0qCSpbdu21fZLSEhQYGCgU1tcXJziuDULAACAMamp\n",
       "qUr90dNTz54920DV3DrcLoDExsZq2bJlWrVqlWbPni2p/MnoSUlJio6OdtwBq6CgQIWFherSpUuN\n",
       "71pVVFSk2267zWmviW3bSkxMlGVZGjFiRLXjly9fzl4JAACABlbZL4AzMzPruK8WbhdA+vXrp7Fj\n",
       "x2r+/Pk6deqUQkNDtW7dOh0/flxJSUmOfvPmzVNycrKOHTumTp06OdoTExMlSUeOHJEkJScna/fu\n",
       "3ZKk559/XlL5Zuu4uDhNnDhRoaGhKikp0ebNm7Vv3z7NnDnzpl5lAQAAABoztwsgUnloWLBggVJS\n",
       "UnTmzBn16tVLW7Zs0YABAxx9LMuSZVkuYxcuXCjLsmTbtizL0po1axz9KwJISEiIBg0apM2bN6ug\n",
       "oEAeHh7q3r27Xn/9dcXHx5s5SQAAAKARcssA4u3traVLl2rp0qVV9klKSnK6IlLh6tWr1z1+SEiI\n",
       "Nm7cWKcaAQAAgFuRR0MXAAAAAMB9EEAAAAAAGEMAAQAAAGAMAQQAAACAMW65CR0AgMYmNbX8JUml\n",
       "pVJentS5s+TjU94WF1f+AoCmjgACAEAjcG3AyMyUoqLKAwnPpQVwq2EJFgAAAABjCCAAAAAAjCGA\n",
       "AAAAADCGAAIAAADAGAIIAAAAAGMIIAAAAACMIYAAAAAAMIYAAgAAAMAYAggAAAAAYwggAAAAAIwh\n",
       "gAAAAAAwhgACAAAAwBgCCAAAAABjCCAAAAAAjCGAAAAAADCGAAIAAADAGAIIAAAAAGMIIAAAAACM\n",
       "IYAAAAAAMIYAAgAAAMAYAggAAAAAYwggAAAAAIwhgAAAAAAwhgACAAAAwBgCCAAAAABjCCAAAAAA\n",
       "jCGAAAAAADCGAAIAAADAGAIIAAAAAGMIIAAAAACMIYAAAAAAMIYAAgAAAMAYz4YuALhw4YJycnJq\n",
       "PT4721dSuLKzsyWV1OoY3bp1k5+fX61rAAAAwI0hgKDB5eTkKCoqqg5HiJSUqcmTJ0nKqtURMjIy\n",
       "1Lt3b5f2uoSj+ghGEuEIAADcWgggaDTWSwqvxbhsSZNrOb5ibFXqFo7qHoykqsMRAABAU0QAQaMR\n",
       "LqkuX7PrOr46dQk3dQ1WAAAAtxICCHAD6hJubmYwAgAAaGq4CxYAAAAAYwggAAAAAIwhgAAAAAAw\n",
       "xi0DSFlZmebOnavg4GD5+fkpOjpaO3bsuO64goICzZs3Tw888IBatGghDw8Pffzxx1X237dvnwYM\n",
       "GCB/f38FBQXp2WefVXFxcX2eCgAAANCkuGUAmTp1qpYvX64pU6Zo5cqVatasmUaNGqW9e/dWOy4n\n",
       "J0dLly5Vfn6+evbsKUmyLKvSvocOHdKQIUNUWlqq5cuXa/r06Vq1apXGjh1b7+cDAAAANBVudxes\n",
       "AwcOaOPGjVq2bJlmzZolSZoyZYp69OihOXPmVBtC+vTpo9OnT6tly5ZKS0tTenp6lX2fe+45tWnT\n",
       "Rrt27VLz5s0lSSEhIYqPj9f27ds1bNiw+j0xAAAAoAlwuysgaWlp8vT01IwZMxxt3t7emjZtmtLT\n",
       "03XixIkqxzZv3lwtW7a87hznzp3Tjh07NHnyZEf4kKQnnnhCzZs316ZNm+p2EgAAAEAT5XYBJCsr\n",
       "S2FhYU7BQJL69u0rqXzpVF19/vnnunz5svr06ePU7uXlpYiICGVl1f6p2AAAAEBT5nYBJD8/X0FB\n",
       "QS7tFW0nT56slzmuPea17rzzznqZAwAAAGiK3G4PSElJiby9vV3afXx8HO/XxxySqpynPuYALly4\n",
       "oJycnFqNzc72lRSu7OxsSbX/57Fbt27y8/Or9XgAAOB+3C6A+Pr6qqyszKW9tLTU8X59zCGpynn4\n",
       "wob6kJOTo6ioqFqOjpSUqcmTJ0mq/ZLAjIwM9e7d26mtLsFIqp9wRDACAKDxcrsAEhQUVOkSqIpl\n",
       "U8HBwfUyx7XH/PE815sjISFBgYGBTm1xcXGKi4urc2249ayXFF7DMdmSJtdy7LXjK1O3YCTVRziq\n",
       "LBgBAFBTqampSk1NdWo7e/ZsA1Vz63C7ABIZGaldu3apqKhILVq0cLTv379fkhQREVHnOXr06CFP\n",
       "T08dPHhQsbGxjvaLFy/q0KFDmjBhQrXjly9fzpcn3LBwSbX9p6UuY6+nruGmLsEKAID6UNkvgDMz\n",
       "M+v4iza4XQCJjY3VsmXLtGrVKs2ePVtS+VKppKQkRUdHq3379pLKn3peWFioLl26yNOzZj+mwMBA\n",
       "DR06VOvXr9eCBQscd9xKSUlRcXExDyOEW6hruLmZ4QgAADQctwsg/fr109ixYzV//nydOnVKoaGh\n",
       "WrdunY4fP66kpCRHv3nz5ik5OVnHjh1Tp06dHO2JiYmSpCNHjkiSkpOTtXv3bknS888/7+j30ksv\n",
       "6f7779fgwYMVHx+vb775Rq+++qpGjBih4cOHmzhVAADqLDW1/CVJpaVSXp7UubP0z3u3KC6u/AUA\n",
       "N8rtAohUHhoWLFiglJQUnTlzRr169dKWLVs0YMAARx/LsmRZlsvYhQsXyrIs2bYty7K0Zs0aR/9r\n",
       "A0hkZKR27NihuXPnatasWQoICND06dO1ZMmSm3+CAADUk2sDRmamFBVVHkhYKQygttwygHh7e2vp\n",
       "0qVaunRplX2SkpKcrohUuHr16g3P079/f+3Zs6dWNQIAAAC3Ird7ECEAAACAhkMAAQAAAGAMAQQA\n",
       "AACAMW65BwSAe+Ip7QAANDwCCAC3wVPaAQBoeAQQAG6Hp7QDANBwCCAA3A5PaQcAoOGwCR0AAACA\n",
       "MQQQAAAAAMYQQAAAAAAYQwABAAAAYAwBBAAAAIAxBBAAAAAAxhBAAAAAABhDAAEAAABgDAEEAAAA\n",
       "gDEEEAAAAADGEEAAAAAAGEMAAQAAAGAMAQQAAACAMQQQAAAAAMYQQAAAAAAYQwABAAAAYAwBBAAA\n",
       "AIAxBBAAAAAAxhBAAAAAABhDAAEAAABgDAEEAAAAgDEEEAAAAADGEEAAAAAAGEMAAQAAAGAMAQQA\n",
       "AACAMQQQAAAAAMYQQAAAAAAYQwABAAAAYIxnQxcAAJAuXLignJycWo3NzvaVFK7s7GxJJbWuoVu3\n",
       "bvLz86v1eAAAbgQBBAAagZycHEVFRdVydKSkTE2ePElSVq1ryMjIUO/evWs9HgCAG0EAAYBGZL2k\n",
       "8BqOyZY0uZZjrx0PAIAJBBAAaETCJdX2GkRdxgIAYAoBBABQLfanAADqEwEEAFAt9qegsUpNLX9J\n",
       "UmmplJcnde4s+fiUt8XFlb8ANC4EEADADWF/ChqbawNGZqYUFVUeSMiqQONGAAEA3JDGtj+lLkvD\n",
       "pPpZHsbSMACoOQIIAKBJqtvSMKk+loexNAwAao4AAgBo0uq6vKsuS8sAADVHAAEANGl1Xd7F8jAA\n",
       "MMstA0hZWZkWLlyolJQUFRYWqmfPnkpMTNTQoUOvO7awsFBz5szR5s2bVVJSon79+uk3v/mNIiMj\n",
       "nfrFxMRo9+7dLuNHjBih999/v97OBQDQ+LA8DACq5pYBZOrUqXr77beVkJCgrl27KikpSaNGjdLO\n",
       "nTvVv3//KsddvXpVP/vZz3T48GHNmTNHbdq00WuvvaaYmBhlZGSoS5cuTv07duyoJUuWOLUFBwff\n",
       "lHMCADQ+LA8DAFduF0AOHDigjRs3atmyZZo1a5YkacqUKerRo4fmzJmjvXv3Vjk2LS1N6enpSktL\n",
       "02OPPSZJGjdunMLCwrRo0SK9+eabTv0DAwM1ceLEm3cyAIBGrTEuDwOAhubR0AWYlpaWJk9PT82Y\n",
       "McPR5u3trWnTpik9PV0nTpyoduydd97pCB+SdPvtt2vcuHF65513dOnSJaf+tm3rypUrOn/+fP2f\n",
       "CAAAANAEuV0AycrKUlhYmJo3b+7U3rdvX0nSoUOHqh1b2Xravn376sKFC8rNzXVqz83Nlb+/vwIC\n",
       "AhQUFKSFCxfq8uXL9XAWAAAAQNPkdkuw8vPzFRQU5NJe0Xby5Mlqx8bExFQ79qc//akkqUuXLhoy\n",
       "ZIjuueceFRcX66233lJiYqJyc3O1YcOGejgTAADQWKWmlr8kqbRUysuTOneWfHzK2659ijvgbtwu\n",
       "gJSUlMjb29ul3eef/49QUlL17Q5LS0tveOwbb7zh1GfSpEmaOXOmVq9erYSEBN177721qh8AADR+\n",
       "1waMzEwpKqo8kHBjMsANl2D5+vqqrKzMpb20tNTx/s0YK0mzZ8+WJH300Uc3XC8AAABwK3G7KyBB\n",
       "QUGVLrPKz8+XVP1tcusyVpI6dOggSTp9+nS1/RISEhQYGOjUFhcXpziu1QIAABiTmpqq1Iq1dP90\n",
       "9uzZBqrm1uF2ASQyMlK7du1SUVGRWrRo4Wjfv3+/JCkiIqLKsREREfrkk09k27Ysy3Ia6+/vr7Cw\n",
       "sGrnPnr0qCSpbdu21fZbvnw5D48CAABoYJX9AjgzM7OODxqF2y3Bio2N1ZUrV7Rq1SpHW1lZmZKS\n",
       "khQdHa327dtLkgoKCpSTk+N016rY2Fh9++23+stf/uJo+/777/XWW29p9OjR8vLykiQVFRW5LNWy\n",
       "bVuJiYmyLEsjRoy4macIAABQpdRU6ZFHyl/Dh0s/+Un5nxVtP/qFP1Dv3O4KSL9+/TR27FjNnz9f\n",
       "p06dUmhoqNatW6fjx48rKSnJ0W/evHlKTk7WsWPH1KlTJ0nlASQ6OlpPPvmkvvjiC8eT0G3b1uLF\n",
       "ix1jMzIyFBcXp4kTJyo0NFQlJSXavHmz9u3bp5kzZ1Z7lQUAAOBmYoM8GprbBRBJSk5O1oIFC5SS\n",
       "kqIzZ86oV69e2rJliwYMGODoY1mW0zIrSfLw8NDWrVv1q1/9SitXrlRJSYn69eun5ORkde3a1dEv\n",
       "JCREgwYN0ubNm1VQUCAPDw91795dr7/+uuLj442dJwAAANDYuGUA8fb21tKlS7V06dIq+yQlJTld\n",
       "EanQsmVLrV69WqtXr65ybEhIiDZu3FgvtQIAAAC3ErfbAwIAAACg4RBAAAAAABhDAAEAAABgDAEE\n",
       "AAAAgDEEEAAAAADGEEAAAAAAGEMAAQAAAGAMAQQAAACAMQQQAAAAAMYQQAAAAAAY49nQBQAAAHMu\n",
       "XLignJycWo3NzvaVFK7s7GxJJbWuoVu3bvLz86v1eABNGwEEAAA3kpOTo6ioqFqOjpSUqcmTJ0nK\n",
       "qnUNGRkZ6t27d63HA2jaCCAAALih9ZLCazgmW9LkWo69djwA90YAAQDADYVLqu01iLqMBQA2oQMA\n",
       "AAAwhgACAAAAwBgCCAAAAABjCCAAAAAAjCGAAAAAADCGAAIAAADAGAIIAAAAAGMIIAAAAACMIYAA\n",
       "AAAAMIYAAgAAAMAYAggAAAAAYzwbugAAAAAgNbX8JUmlpVJentS5s+TjU94WF1f+QtNHAAEAAECD\n",
       "uzZgZGZKUVHlgaR374atC/WPJVgAAAAAjCGAAAAAADCGJVgAAKBRuHDhgnJycmo1NjvbV1K4srOz\n",
       "JZXUuoZu3brJz8+v1uMBXB8BBAAANAo5OTmKioqq5ehISZmaPHmSpKxa15CRkaHebDoAbioCCAAA\n",
       "aFTWSwqv4ZhsSZNrOfba8QBuPgIIAABoVMIl1fYaRF3GAjCDAAIAAFCNuuxNkepnfwp7U3ArIYAA\n",
       "AABUo257U6T62J/C3hTcSgggAAAAN6Cu+0vqsrcFuJUQQAAAAG5AXfeX3Iz9KSwPQ1NEAAEAAGii\n",
       "WB6GpogAAgAA0MSxPAxNCQEEAACgiWuMy8OAqng0dAEAAAD/X3t3H99T/f9x/PkZs7G5nIsZsWxG\n",
       "hrbKtVykmouUwqRviUQpYvpa6Pvjm4tUX9JX3Xwr+g65CFOq3ZRakUQbQwlFSq7mKtHYZrO9f3+4\n",
       "7fNtzVi7OOfMHvfb7dzU+3Pen/M8O2d8Xp/zPu8DoOygAAEAAABgGQoQAAAAAJahAAEAAABgGQoQ\n",
       "AAAAAJYpk7NgXbhwQZMmTdLbb7+tM2fOqGXLlpo2bZpuv/32q/Y9c+aMoqOj9d577yktLU2tW7fW\n",
       "rFmzFB4enmfdTZs2KTo6Wtu3b1eVKlUUGRmp559/Xj4+PiWxWwAAAI5RlIckFscDEiUekuhUZbIA\n",
       "GTx4sFatWqWoqCg1btxYMTEx6tmzp9atW6cOHTrk2y87O1u9evXSt99+q+joaPn5+Wnu3Lnq0qWL\n",
       "kpKSFBwc7F53x44d6tatm0JDQzV79mwdOnRIM2fO1L59+7RmzRordhMAAMA2RXtIYtEfkCjxkESn\n",
       "KnMFSGJiopYvX66ZM2dq7NixkqSHHnpIzZs3V3R0tL766qt8+8bGxmrz5s2KjY3VfffdJ0mKjIxU\n",
       "SEiIJk+erCVLlrjXnThxovz8/LR+/Xr5+vpKkgIDAzVs2DB9+umnuuOOO0pwLwEAAJyhKA85LOoD\n",
       "FuFMZa4AiY2NVfny5TV8+HB3m5eXl4YOHaqJEyfqyJEjqlevXr59/f393cWHJNWsWVORkZFavHix\n",
       "MjMz5enpqd9//13x8fEaO3asu/iQpEGDBikqKkorVqygAAEAAGVCUR5yyAMSr01l7ib07du3KyQk\n",
       "JFdhIEmtWrWSdGno1JX6Xu4yXqtWrZSamqq9e/dKknbu3KmLFy/qlltuybWep6enwsLCtH174S8l\n",
       "AgAAAKVZmStAkpOTVbdu3TztOW1Hjx4tct/k5ORc7X/k7+9/xW0AAAAA17IyV4CkpaXJy8srT7u3\n",
       "t7f79fykp6cXqG/On/mte6VtAAAAANeyMncPSMWKFXXhwoU87enp6e7Xi9o358/81rVzOrg9RexX\n",
       "mP4F7XOtZStKrr/Sz6nZrrXj+cd+TsvGuVa093ba8fxjP6dl41wr2ns77Xj+sZ/Tsll1rsEeZa4A\n",
       "qVu37mWHQOUMmwoICChy35yhVzntf173StuQpKioKFWtWjVX28CBAzVw4MAr9iuIos4IUZIzSlyr\n",
       "2Up6Fg6nZrtWj2dx9C+p9+Zcs6d/Sb63U7NxrtnTvyTf26nZ7J7JatmyZVq2bFmutrNnz9qU5tpR\n",
       "5gqQ8PBwrV+/XikpKapcubK7PSEhQZIUFhaWb9+wsDB9+eWXMsbI5XLl6uvj46OQkBBJUvPmzVW+\n",
       "fHlt2bJF/fr1c6+XkZGhHTt26P77779ixtmzZxf7nNVNmzZVUlLSX+rz8cfVtXZtdUnShQseSk5O\n",
       "V9266+XllS1Jioj4Td27//aXMhRXtj/as6eiHnxQWrx4iW64oXDD20oiW3HkKo3ZrtXj6eRsnGuF\n",
       "49Tj6eRsnGuF49Tj6eRsJX2uFdTlvgDetm1bEZ5vAkmSKWMSEhKMy+UyM2fOdLelp6eb4OBg065d\n",
       "O3V491UAABl4SURBVHdbcnKy2bNnj8nMzHS3LV++3LhcLhMbG+tuO3nypKlWrZoZOHBgru306NHD\n",
       "BAQEmJSUFHfb/PnzjcvlMmvXrr1stqSkJCPJJCUlFXk/y5KkJGOkS386iVNzGUO2wnJqNqfmMoZs\n",
       "heXUbE7NZQzZCsup2Zyayxg+rxWHMncFpHXr1urfv78mTJigEydOKCgoSAsXLtTBgwcVExPjXm/8\n",
       "+PFatGiRDhw4oAYNGkiS+vXrp7Zt22rIkCHavXu3+0noxhg999xzubYzffp0tW/fXp07d9awYcN0\n",
       "+PBhvfzyy4qIiNCdd95p6T4DAAAATlHmZsGSpEWLFmnMmDF6++23NXr0aGVlZSkuLk4dO3Z0r+Ny\n",
       "uXINs5IkDw8PrVmzRgMGDNCcOXMUHR2t2rVr6/PPP1fjxo1zrRseHq74+HhVrFhRY8eO1fz58/Xo\n",
       "o48qNjbWkn0EAAAAnKjMXQGRLk2P+9JLL+mll17Kd52YmJhcV0RyVKtWTfPmzdO8efOuup0OHTpo\n",
       "48aNRcoKAAAAXEvK5BUQAAAAAPagAAEAAABgGQoQAAAAAJahAAEAAABgmTJ5EzpKv2XLLi2SlJ4u\n",
       "hYRI48dL3t6X2gYOvLQAAADAWShAUCpRYAAAAJRODMECAAAAYBkKEAAAAACWYQgWAAAAbMf9nWUH\n",
       "BQgAAABsR4FRdjAECwAAAIBlKEAAAAAAWIYhWEAZwdhaAADgBBQgQBlBgQEAAJyAAgQoRlxlAAAA\n",
       "uDIKEKAYUWAAAABcGTehAwAAALAMBQgAAAAAyzAECwAAoAzhfkXYjQIEAACgmDn5Qz4FBuxGAQIA\n",
       "AFDM+JAP5I8CBAAAlEpOvsoAIH8UIAAAoFSiwABKJ2bBAgAAAGAZChAAAAAAlmEIFgCUQox9BwCU\n",
       "VhQgAFAKUWDAKhS7AIobBQgAXAEfvlDWcY4DKG4UIABwBXz4AgCgeFGAAADgAFxtA1BWUIAAAOAA\n",
       "FBgAygoKEAC245tfAADKDgoQALajwAAAoOzgQYQAAAAALMMVEABAsWJIHQDgSihAAADFigIDAHAl\n",
       "DMECAAAAYBkKEAAAAACWYQgWAKDM4P4UALAfBQgAoMygwAAA+zEECwAAAIBlKEAAAAAAWIYCBAAA\n",
       "AIBlKEAAAAAAWIYCBAAAAIBlymQBcubMGQ0fPly1atWSr6+vbrvtNm3fvr3A/Y8cOaLIyEhVr15d\n",
       "VatWVZ8+ffTzzz/nWS8wMFAeHh55lhEjRhTn7gAAAAClRpmbhjc7O1u9evXSt99+q+joaPn5+Wnu\n",
       "3Lnq0qWLkpKSFBwcfMX+586dU9euXZWSkqJnn31W5cuX1+zZs9W5c2ft2LFDNWrUcK/rcrkUHh6u\n",
       "p59+Otd7hISElMi+AQAAAE5X5gqQ2NhYbd68WbGxsbrvvvskSZGRkQoJCdHkyZO1ZMmSK/afO3eu\n",
       "fvzxR23ZskU333yzJKlHjx5q3ry5Zs2apenTp7vXNcaoXr16euCBB0puhwAAAIBSpMwNwYqNjZW/\n",
       "v7+7+JCkmjVrKjIyUu+//74yMzOv2r9169bu4kOSmjRpom7dumnFihV51jfGKDMzU+fPny++nbDJ\n",
       "spzHBzuQU7M5NZdEtsJyajan5pLIVlhOzebUXBLZCsup2ZyaC0VX5gqQ7du366abbsrT3qpVK6Wm\n",
       "pmrv3r359s3Ozta3336rW2655bL99+/fn6fQ+Pzzz1WpUiVVrlxZ119/vebMmVP0nbCJk/8icGo2\n",
       "p+aSyFZYTs3m1FwS2QrLqdmcmksiW2E5NZtTc6HoylwBkpycrLp16+Zpz2k7evRovn1Pnz6tjIyM\n",
       "Ave/8cYb9dxzz+ndd9/VW2+9pQYNGmjMmDEaP358UXcDAAAAKJVK9T0gxhhduHChQOt6e3tLktLT\n",
       "0+Xl5ZXv62lpafm+R85rBe3//vvv51pnyJAh6tGjh15++WWNGjVK9erVK1B2AAAA4FpRqq+AfPHF\n",
       "F6pUqVKBlpyhVRUrVrxs0ZKenu5+PT85rxW2vyRFRUXp4sWL+uKLLwq2kwAAAMA1pFRfAbnhhhu0\n",
       "YMGCAq3r7+8v6dJQqcsNs0pOTpYkBQQE5PseNWrUkJeXl3vdv9pfkurXry/p0nCuP8u5erJnz54r\n",
       "voddzp49q23bttkd47Kcms2puSSyFZZTszk1l0S2wnJqNqfmkshWWE7N5tRcOZ/TrjRqBldhypj+\n",
       "/fsbf39/k52dnat92LBhxtfX12RkZFyxf6tWrUzr1q3ztN9xxx0mODj4qtv/8MMPjcvlMu+8806e\n",
       "1xYvXmwksbCwsLCwsLCwOHxZvHjxVT/34fJK9RWQwujXr59iY2P17rvvqm/fvpKkU6dOaeXKlerd\n",
       "u7c8PT3d6x48eFCpqalq2rRprv7jx49XUlKSeyreH374QevWrdO4cePc6/3222+qUqWKypUr527L\n",
       "zMzUCy+8IC8vL3Xt2jVPtoiICC1evFiBgYFXHcoFAAAA66WlpenAgQOKiIiwO0qp5TLGGLtDWCk7\n",
       "O1sdO3bUd999p3HjxrmfhH748GFt2bJFjRs3dq/bpUsXbdiwQdnZ2e62c+fOKTw8XCkpKfr73/+u\n",
       "8uXL6+WXX5YxRjt27JCfn58kacGCBZo2bZr69++vwMBAnT59WkuXLtWuXbs0Y8YMPfPMM5bvOwAA\n",
       "AGC3MncFxMPDQ2vWrNG4ceM0Z84cpaWlqXXr1lq0aFGu4kOSXC6XXC5XrjZfX1+tX79eUVFRmjZt\n",
       "mrKzs9W1a1fNnj3bXXxIUsuWLRUaGqrFixfr5MmTqlChgsLDw7Vy5Ur3lRcAAACgrClzV0AAAAAA\n",
       "2KdUT8MLAAAAoHShAMFVbdu2TXfffbf8/Pzk4+OjFi1a6NVXX7Vk2+fPn9fkyZPVvXt31ahRQx4e\n",
       "Hlq4cGGe9ebNm6fOnTvL399f3t7eatiwoQYOHKjdu3dbkjPH4MGD5eHhke9yuSmcrXThwgU988wz\n",
       "CggIUKVKldS2bVvFx8fbmkkq+HG2w9atW3XPPfcoICBAPj4+uuGGGzR16lRHTL+YlJSk7t27q2rV\n",
       "qqpSpYoiIiL0zTffWJqhMMcuMzNTzZo1k4eHh2bNmmVrNmOMFixYoLvvvlsNGjSQr6+vWrRooenT\n",
       "pxf4QbclkSvHnj171L17d1WuXFl+fn4aNGiQTp06VSK58rNlyxaNHDlSoaGh8vX1VcOGDTVgwADt\n",
       "27fP0hwFNX36dHl4eKhFixa25li/fn2+/xYkJiZalqOg51tiYqKeeOIJ3XzzzfL09JSHh/UfEXft\n",
       "2qX+/fsrKChIPj4+8vPzU/v27bVkyRLLs6Bklbl7QPDXfPLJJ+rdu7duvvlmTZo0Sb6+vvrxxx91\n",
       "5MgRS7Z/8uRJTZ06VQ0bNlRYWJjWr1+f574cSdqxY4eCgoLUp08fVa9eXT/99JPmzZunuLg4JSUl\n",
       "KSQkxJK8jz/+uO68885cbdnZ2Xr88cd1/fXXq27dupbkyM/gwYO1atUqRUVFqXHjxoqJiVHPnj21\n",
       "bt06dejQwbZcBT3OVtu5c6c6duyogIAAjRkzRjVq1NCmTZs0efJkJSUlafXq1bZl27Ztmzp27KiG\n",
       "DRvqn//8p7KysjR37lx17txZiYmJlp3zhTl2r776qg4dOiRJJXqcC5Lt/PnzeuSRR9SuXTuNGDFC\n",
       "tWvXdh/jzz77TJ9//rktuSTp8OHD6tSpk6pXr64ZM2YoJSVFM2fO1M6dO5WYmJhr1saS9OKLL2rz\n",
       "5s3q37+/WrZsqeTkZL322mu66aab9PXXXys0NNSSHAVx+PBhPf/88/Lx8XHE3yGSNHr0aLVq1SpX\n",
       "W1BQkGXbL+j5tmbNGr311lu68cYbFRQUZEuBefDgQZ07d06DBw9WQECAUlNTFRsbq4ceekgHDhzQ\n",
       "s88+a3kmlBA75wCGs509e9bUqVPH9O3b17YMFy5cMMePHzfGGLN161bjcrnMwoULC9Q3KSnJuFwu\n",
       "M2nSpJKMeFVffvmlcblcZsaMGbbmSEhIMC6Xy8yaNcvdlp6eboKDg0379u1tTFa041ySJk6caFwu\n",
       "l9m9e3eu9ocffti4XC5z5swZm5IZ07NnT+Pn52dOnz7tbktOTjaVK1e29Hf2rx6748ePm2rVqplp\n",
       "06blOR/tyJaRkWE2b96cp++UKVOMy+Uy8fHxtuQyxpgRI0YYHx8fc+jQIXdbfHy8cblc5s033yz2\n",
       "XPnZtGmTyczMzNW2b98+4+3tbR588EHLchTEgAEDzO233266dOlimjdvbmuWdevWGZfLZVatWmVr\n",
       "joKeb8ePHzfp6enGGGOefPJJ43K5LM2Zn6ysLBMWFmYaNGhgdxQUI4ZgIV9Lly7ViRMnNH36dEmX\n",
       "vin845TEVqhQoYJq164t6dJQib+iYcOGkmTZt4T5Wbp0qVwulx544AFbc8TGxqp8+fIaPny4u83L\n",
       "y0tDhw7V5s2bLbuqdTlFOc4lKed5PDnZcvj7+6tcuXKqUKGCHbEkSV9++aVuv/12Va9ePVeuTp06\n",
       "KS4uTqmpqZbk+KvHbvz48WratKn+9re/lXS0AmXz9PRU27Zt87T36dNHkvT999/bkkuSVq1apbvu\n",
       "ukv169d3t3Xr1k0hISFasWJFsefKT7t27VS+fO4BE8HBwWrWrFmJ/HwKa8OGDVq1apVeeeUVGWMc\n",
       "cwXEGKOUlBRdvHjRlu0X9HyrXbu2vLy8rIpVYB4eHqpfv77t/5ajeFGAIF/x8fGqUqWKDh06pCZN\n",
       "mqhy5cqqWrWqnnjiiRIbG11Uv/76q06cOKGtW7dqyJAhqlOnjoYMGWJbnszMTK1YsUIdOnRQgwYN\n",
       "bMshSdu3b1dISIh8fX1ztecMDdixY4cdsRztkUceUZ06dTR06FB98803OnTokJYvX67XX39dTz31\n",
       "lK0PDM3IyLjs9itVqqSMjAzt3LnThlRXlpiYqEWLFumVV16xO8pVHTt2TJJUs2ZNW7Z/5MgRnTx5\n",
       "Urfcckue11q1aqXt27fbkOp/jDE6fvy4bT+fP8vKytKoUaM0bNgwRw0Jk6QhQ4aoatWqqlixom67\n",
       "7TYlJSXZHcnxUlNTderUKe3fv1+zZ8/W2rVrFR0dbXcsFCPuAUG+9u3bp4sXL6pPnz569NFH9eKL\n",
       "L2rdunV69dVXdebMGS1dutTuiHnUq1dPGRkZkqRGjRrpiy++UL169WzLs3btWp0+fdqSb3uvJjk5\n",
       "+bL3oOS0HT161OpIjhcQEKCvvvpKPXv2VHh4uLv9H//4h6ZMmWJjMqlJkybavHmzsrOz3TeLZmRk\n",
       "KCEhQZLzjqcxRqNGjdL999+vNm3a6MCBA3ZHuqKXXnpJVatWVY8ePWzZfs6EFfn9zp4+fVqZmZm2\n",
       "fSu8ZMkSHT16VNOmTbNl+3/2+uuv6+DBgyVyz05heXl5qV+/furZs6dq1qypXbt2aebMmbr11lu1\n",
       "adMmhYWF2R3RscaOHas333xTklS+fHnNmTMn19V7lH4UIMjXuXPnlJqaqhEjRri/sezTp48yMjL0\n",
       "xhtvaMqUKQoODrY5ZW5r165Venq6du/erVmzZunOO+/Uxo0bcw1hsNLSpUtVoUIFRUZG2rL9P0pL\n",
       "S7vs5XVvb2/368jt+PHj7g+g8+bNk5+fn+Li4jR9+nTVqVNHTz75pG3ZnnjiCY0YMUJDhw5VdHS0\n",
       "srKyNG3aNPc39047ngsWLNB3332nd9991+4oV/X888/rs88+03/+8x9VqVLFlgw5x+9qv7N2FCDf\n",
       "f/+9nnzySbVv314PP/yw5dv/s19//VWTJk3SpEmTcj0Q2G7t2rVTu3bt3P9/1113qV+/fmrZsqUm\n",
       "TJigjz76yMZ0zhYVFaXIyEgdPXpUS5Ys0ciRI1WxYkVHnG8oHgzBQr5yhncMHDgwV3vO/3/99deW\n",
       "Z7qazp07KyIiQlFRUdqwYYNOnDhh2zfV586d0/vvv6+IiIhc4/TtUrFixcsOnUtPT3e/jtymTp2q\n",
       "I0eOaN26dRo6dKj69Omj+fPn6+GHH9Yzzzyj06dP25btscce08SJE7V06VKFhoaqZcuW+vnnn93D\n",
       "FP481M5Ov//+uyZMmKDo6Ghbr0gWxPLly/V///d/evTRR/XYY4/ZliPn99Fpv7PHjh1Tr169VL16\n",
       "dcXGxjriPot//OMfqlmzpkaNGmV3lKsKCgrSPffco3Xr1jnqfjenadKkiW677TY9+OCD+uijj9St\n",
       "WzeNGTPGcV+soPAoQJCvgIAASVKdOnVytefczPbbb79ZnumvaNSokcLCwiydb/2PVq9erbS0NEcM\n",
       "v5IuDdu43LCcnKEeOccb/7Nx40aFh4fn+dn07t1bqamptt83M23aNB0/flwbN27Uzp07lZCQoKys\n",
       "LEmybBregpg5c6YyMzMVGRmpAwcO6MCBAzp8+LAk6fTp0zpw4IAyMzNtTil9+umnGjRokO666y69\n",
       "/vrrtmbJGXp1uWcHJScny8/Pz/KrH2fPnlWPHj30+++/6+OPP5a/v7+l27+cffv2ad68eRo1apQO\n",
       "Hz7sPr/S09OVkZGhX375xXH/VtWvX18ZGRk6f/683VFKjb59++rs2bP64Ycf7I6CYkIBgnzl3PyY\n",
       "80EhR86H2Fq1alme6a9KS0uz5WFK0qUx0pUrV9bdd99ty/b/LDw8XHv37lVKSkqu9px7BhiPnFdm\n",
       "Zqb7A/2f2yXZNqvNH1WrVk3t27d333gbHx+v6667Tk2bNrU52f8cOnRIv/32m0JDQ9WoUSM1atRI\n",
       "nTp1knRpuFOjRo20Z88eWzMmJCTo3nvvVevWrbVixQrb/t7IUa9ePdWqVUtbtmzJ81piYqLlv6/p\n",
       "6enq3bu3fvzxR8XFxTnm/Dpy5Iiys7P11FNPuc+tRo0aKTExUXv37tX111+vqVOn2h0zl59++kkV\n",
       "K1Z01FVKp8u58mH37yWKD0cS+cq5b+Gtt97K1T5//nx5enqqS5cuNqTKKysr67LfcCUmJuq7777T\n",
       "rbfeanmmkydPKj4+Xvfee697vLbd+vXrp6ysLPeNfdKl4R0xMTFq27at44fG2OGmm27Stm3b8jyQ\n",
       "a9myZSpXrpxatmxpU7LLW758ubZu3aoxY8bYHSWXp556SqtXr861vPHGG5IuzRC0evVqBQYG2pZv\n",
       "z5496tWrlxo1aqS4uDjHTEXat29fxcXF5foS6LPPPtO+ffvUv39/y3JkZWVpwIABSkhI0MqVK9Wm\n",
       "TRvLtn01LVq00HvvvZfr3HrvvfcUGhqqhg0bavXq1Ro6dKgt2U6ePJmn7ZtvvtEHH3yQ54G1uORy\n",
       "P7PMzEwtWrRIfn5+jpvhDIXHTejIV1hYmB555BH997//1cWLF9WpUyetX79esbGxmjhxomWX3197\n",
       "7TWdOXPGfeXlgw8+0MGDByVd+mCTnZ2t6667Tvfff7+aNWsmHx8f7dy5UzExMfL399eECRMsyflH\n",
       "y5cvV1ZWlmOGX0lS69at1b9/f02YMEEnTpxQUFCQFi5cqIMHDyomJsbueFc9znbcDDxu3DitWrVK\n",
       "t956q0aOHKkaNWooLi5OH3/8sYYNG2brEJQNGzZoypQpioiIUI0aNfT1119rwYIF6tGjh0aPHm1p\n",
       "lqsdu/Dw8FyziElyz4IVGhpaolcJr5bN5XIpIiJCZ86cUXR0tD788MNc/YODgy/7nJCSzlWlShVN\n",
       "nDhRK1euVNeuXTV69GilpKToX//6l1q2bGnp9OJPP/20PvzwQ/Xu3VunTp3S4sWLc73+4IMPWpbl\n",
       "z/z8/HTPPffkaZ89e7Yk2XoFesCAAapUqZLatWun2rVra/fu3XrzzTfl6+urF154wdIsBTnffvnl\n",
       "F7399tuSpK1bt0qSpk+fLmOMAgMDLTnOw4cPV0pKijp16qSAgAAdO3ZMS5Ys0d69exUTE6Ny5cqV\n",
       "eAZYxJ7nH6K0yMzMNM8995wJDAw0FSpUMCEhIebf//63pRkCAwONy+UyLpfLeHh4GA8PD/d///LL\n",
       "LyYjI8OMGTPG3HjjjaZq1aqmQoUKJigoyIwcOdIcO3bM0qw52rVrZ/z9/U12drYt289Penq6GTdu\n",
       "nKlbt67x9vY2bdq0MZ988ondsYwxVz/OdklISDDdu3c3VapUMRUqVDBNmzY1M2bMMFlZWbZlMsaY\n",
       "/fv3m4iICFOrVi3j7e1tmjVrZl588cU8T6y2QmGO3c8//1ziT0IvSLacHDntf16GDBliS64cu3bt\n",
       "MhEREcbHx8fUqFHDPPTQQ+bEiRMlkik/Xbp0yffn4+HhYWmWgurSpYtp0aKFrRnmzJlj2rRpY/z8\n",
       "/Iynp6epV6+eGTRokNm/f7/lWQpyvuU8uf3P67hcLtO1a1dLcr7zzjvmjjvuMP7+/sbT09P4+fmZ\n",
       "nj17mvj4eEu2D+u4jGEaBgAAAADW4B4QAAAAAJahAAEAAABgGQoQAAAAAJahAAEAAABgGQoQAAAA\n",
       "AJahAAEAAABgGQoQAAAAAJahAAEAAABgGQoQAAAAAJahAAEAAABgGQoQAAAAAJahAAEAAABgGQoQ\n",
       "AAAAAJahAAEAAABgGQoQAAAAAJahAAEAAABgGQoQAAAAAJahAAEAAABgGQoQAAAAAJahAAEAAABg\n",
       "GQoQAAAAAJahAAEAAABgGQoQAAAAAJahAAEAAABgGQoQAAAAAJahAAEAAABgGQoQAAAAAJahAAEA\n",
       "AABgGQoQAAAAAJahAAEAAABgGQoQAAAAAJahAAEAAABgGQoQAAAAAJahAAEAAABgGQoQAAAAAJah\n",
       "AAEAAABgGQoQAAAAAJahAAEAAABgGQoQAAAAAJb5fwyteGzLk3n6AAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This feature selection plots forest importances\n",
    "#http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html#example-ensemble-plot-forest-importances-py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Build a classification task using 3 informative features\n",
    "X, y = make_classification(n_samples=1000,\n",
    "                           n_features=10,\n",
    "                           n_informative=3,\n",
    "                           n_redundant=0,\n",
    "                           n_repeated=0,\n",
    "                           n_classes=2,\n",
    "                           random_state=0,\n",
    "                           shuffle=False)\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "# Comment these out to use the base example\n",
    "X = np.array(allTrain)\n",
    "y = clsTrain\n",
    "\n",
    "forest.fit(X, y)\n",
    "\n",
    "importances = forest.feature_importances_ #array with importances of each feature\n",
    "\n",
    "idx = np.arange(0, X.shape[1]) #create an index array, with the number of features\n",
    "\n",
    "features_to_keep = idx[importances > np.mean(importances)] #only keep features whose importance is greater than the mean importance\n",
    "#should be about an array of size 3 (about)\n",
    "# print features_to_keep.shape\n",
    "\n",
    "x_feature_selected = X[:,features_to_keep] #pull X values corresponding to the most important features\n",
    "\n",
    "# print x_feature_selected\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f],\":\"+ Labels[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "# interesting enough this feature selection method doesn't fix the same fields as the RFE model\n",
    "from IPython.display import Image\n",
    "Image(\"forest_feature_selection.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I was able to use two different feature selection methods to find the most informative features.  Now I'll par down my training and testing data to just one or two features and see if everything is just as accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'attitude_roll', 1: 'attitude_pitch', 2: 'attitude_yaw', 3: 'rotation_rate_x', 4: 'rotation_rate_y', 5: 'rotation_rate_z', 6: 'gravity_x', 7: 'gravity_y', 8: 'gravity_z', 9: 'user_acc_x', 10: 'user_acc_y', 11: 'user_acc_z', 12: 'magnetic_field_x', 13: 'magnetic_field_y', 14: 'magnetic_field_z'}\n"
     ]
    }
   ],
   "source": [
    "print Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Reducing traing down to just acc_x and acc_z\n",
    "\n",
    "def reduceToXZ(input_array):\n",
    "    output_array = []\n",
    "    for i in range(len(input_array)):\n",
    "        temp = []\n",
    "        temp.append(input_array[i][9]) # user_acc_x\n",
    "        temp.append(input_array[i][11]) # user_acc_z\n",
    "        output_array.append(temp)\n",
    "    \n",
    "    return output_array\n",
    "    \n",
    "trainAxAz = reduceToXZ(allTrain)\n",
    "testAxAz = reduceToXZ(allTest)\n",
    "walkAxAz = reduceToXZ(walkTest)\n",
    "sitAxAz = reduceToXZ(sitTest)\n",
    "carAxAz = reduceToXZ(carTest)\n",
    "jogAxAz = reduceToXZ(jogTest)\n",
    "stairsAxAz = reduceToXZ(stairsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.014446460000000005, 0.0060615909999999955]\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "print trainAxAz[0]\n",
    "print len(trainAxAz)\n",
    "print len(clsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM on reduced elements\n",
    "\n",
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear')\n",
    "svc.fit(trainAxAz, clsTrain)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for all test data: 0.3\n",
      "Walking: Score for walk test  0.0 :Results  [1 2 2 2 2 2]\n",
      "Sitting: Score for sit test  1.0 :Results  [1 1 1 1 1 1]\n",
      "Car drive: Score for car test  0.0 :Results  [1 1 1 1 1 1]\n",
      "Jogging: Score for jog test  0.5 :Results  [4 3 4 3 1 3]\n",
      "Stairs: Score for stairs test  0.0 :Results  [1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Machine learning Output on \n",
    "\n",
    "svcwalkResults = svc.predict(walkAxAz)\n",
    "svcsitResults = svc.predict(sitAxAz)\n",
    "svccarResults =  svc.predict(carAxAz)\n",
    "svcjogResults =  svc.predict(jogAxAz)\n",
    "svcstairsResults =  svc.predict(stairsAxAz)\n",
    "\n",
    "print \"Score for all test data:\",svc.score(testAxAz, clsTest)\n",
    "# In multi-label classification, this is the subset accuracy which is a harsh metric since you require for \n",
    "# each sample that each label set be correctly predicted.\n",
    "\n",
    "# print \"Column Data Types\"\n",
    "# print dataType.values()\n",
    "print \"Walking: Score for walk test \",svc.score(walkAxAz, [0,0,0,0,0,0]),\":Results \", svcwalkResults\n",
    "print \"Sitting: Score for sit test \",svc.score(sitAxAz, [1,1,1,1,1,1]),\":Results \", svcsitResults\n",
    "print \"Car drive: Score for car test \",svc.score(carAxAz, [2,2,2,2,2,2]),\":Results \", svccarResults\n",
    "print \"Jogging: Score for jog test \",svc.score(jogAxAz, [3,3,3,3,3,3]),\":Results \", svcjogResults\n",
    "print \"Stairs: Score for stairs test \",svc.score(stairsAxAz, [4,4,4,4,4,4]),\":Results \", svcstairsResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
